# VTB-NLP-course homework
Задание 1. 
Выполнить обработку корпуса текста (на русском языке), применить TF-IDF, применить разные методы снижения размерности, сравнить их результаты (описать выводы из сравнения).

Задание 2. 
Построить тематическую модель с помощью BigARTM. Провести эксперименты с разным значением параметров.

Задание 3. Самостоятельно обучить word2vec на корпусе текста. Сравнить предобученные w2v (не обязательно из примера) со своими по качеству (accuracy) решения задачи классификации текста https://www.kaggle.com/competitions/sentiment-analysis-in-russian/data?select=train.json

 Задание 4. Дообучить BERT для анализа тональности на датасете IMBD без использования API. Настроить его гиперпараметры.
 
 Задание 5
Решить задачу кластеризации текста.
Сравнить результаты кластеризации для разных эмбеддингов Word2Vec и BERT. Использовать как минимум 2 алгоритма кластеризации и настроить их гиперпараметры. Визуализировать результат.

Задание 6
Обучить сквозную (end-to-end) модели на задаче кластеризации из практики.  Сравнить с k-Means, DBSCAN, Spectral Clustering.
